{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780507ca",
   "metadata": {},
   "source": [
    "# Reinforcement Learning with Ray RLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2856c7b0",
   "metadata": {},
   "source": [
    "\n",
    "You can run this notebook directly in\n",
    "[Colab](https://colab.research.google.com/github/maxpumperla/learning_ray/blob/main/notebooks/ch_04_rllib.ipynb).\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/maxpumperla/learning_ray/blob/main/notebooks/ch_04_rllib.ipynb\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea5e1f7",
   "metadata": {},
   "source": [
    "For this chapter you need to install the following dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d6d409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray[rllib]==2.2.0 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (2.2.0)\n",
      "Requirement already satisfied: attrs in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (23.1.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (8.1.6)\n",
      "Requirement already satisfied: filelock in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (3.12.2)\n",
      "Requirement already satisfied: jsonschema in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (4.19.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (1.0.5)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (4.24.0)\n",
      "Requirement already satisfied: pyyaml in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (6.0.1)\n",
      "Requirement already satisfied: aiosignal in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (1.4.0)\n",
      "Requirement already satisfied: requests in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (2.31.0)\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (20.21.0)\n",
      "Requirement already satisfied: grpcio>=1.32.0 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (1.57.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (1.24.3)\n",
      "Requirement already satisfied: pandas in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (2.0.3)\n",
      "Requirement already satisfied: tabulate in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (0.9.0)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (2.6.2)\n",
      "Requirement already satisfied: dm-tree in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (0.1.8)\n",
      "Requirement already satisfied: gym<0.24.0,>=0.21.0 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (0.23.1)\n",
      "Requirement already satisfied: lz4 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (4.3.2)\n",
      "Requirement already satisfied: matplotlib!=3.4.3 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (3.7.2)\n",
      "Requirement already satisfied: scikit-image in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (0.21.0)\n",
      "Requirement already satisfied: scipy in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (1.10.1)\n",
      "Requirement already satisfied: typer in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (0.9.0)\n",
      "Requirement already satisfied: rich in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from ray[rllib]==2.2.0) (13.5.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from gym<0.24.0,>=0.21.0->ray[rllib]==2.2.0) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from gym<0.24.0,>=0.21.0->ray[rllib]==2.2.0) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from gym<0.24.0,>=0.21.0->ray[rllib]==2.2.0) (6.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (6.0.1)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from virtualenv>=20.0.24->ray[rllib]==2.2.0) (0.3.7)\n",
      "Requirement already satisfied: platformdirs<4,>=2.4 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from virtualenv>=20.0.24->ray[rllib]==2.2.0) (3.10.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from jsonschema->ray[rllib]==2.2.0) (2023.7.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from jsonschema->ray[rllib]==2.2.0) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from jsonschema->ray[rllib]==2.2.0) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from jsonschema->ray[rllib]==2.2.0) (0.9.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from pandas->ray[rllib]==2.2.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from pandas->ray[rllib]==2.2.0) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from requests->ray[rllib]==2.2.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from requests->ray[rllib]==2.2.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from requests->ray[rllib]==2.2.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from requests->ray[rllib]==2.2.0) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from rich->ray[rllib]==2.2.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from rich->ray[rllib]==2.2.0) (2.16.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from rich->ray[rllib]==2.2.0) (4.5.0)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from scikit-image->ray[rllib]==2.2.0) (3.1)\n",
      "Requirement already satisfied: imageio>=2.27 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from scikit-image->ray[rllib]==2.2.0) (2.31.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from scikit-image->ray[rllib]==2.2.0) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from scikit-image->ray[rllib]==2.2.0) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from scikit-image->ray[rllib]==2.2.0) (0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from importlib-metadata>=4.10.0->gym<0.24.0,>=0.21.0->ray[rllib]==2.2.0) (3.16.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->ray[rllib]==2.2.0) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.4.3->ray[rllib]==2.2.0) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install \"ray[rllib]==2.2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b17e3aa",
   "metadata": {},
   "source": [
    "\n",
    "To import utility files for this chapter, on Colab you will also have to clone\n",
    "the repo and copy the code files to the base path of the runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8206edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/maxpumperla/learning_ray\n",
    "%cp -r learning_ray/notebooks/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f8c77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "\n",
    "class Env:\n",
    "\n",
    "    action_space: gym.spaces.Space\n",
    "    observation_space: gym.spaces.Space\n",
    "\n",
    "    def step(self, action):\n",
    "        ...\n",
    "\n",
    "    def reset(self):\n",
    "        ...\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72525bf",
   "metadata": {},
   "source": [
    "In `maze.py` we set `num_rollout_workers=0` for this notebook, so that the code works in Colab. In the book itself we use 2 rollout workers to show that experience collection can be distributed by RLlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a6734a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/air/_internal/remote_storage.py:4: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import packaging\n",
      "/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.logging')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/tune/logger/tensorboardx.py:35: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  VALID_NP_HPARAMS = (np.bool8, np.float32, np.float64, np.int32, np.int64)\n",
      "/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if (distutils.version.LooseVersion(tf.__version__) <\n",
      "2023-08-16 17:53:59,751\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2023-08-16 17:54:00,569\tINFO algorithm_config.py:2503 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "2023-08-16 17:54:00,570\tINFO algorithm_config.py:2503 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/air/_internal/remote_storage.py:4: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m   from pkg_resources import packaging\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m   declare_namespace(pkg)\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.logging')`.\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m   declare_namespace(pkg)\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m   declare_namespace(pkg)\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/tune/logger/tensorboardx.py:35: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m   VALID_NP_HPARAMS = (np.bool8, np.float32, np.float64, np.int32, np.int64)\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=33591)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(DQN pid=33591)\u001b[0m 2023-08-16 17:54:03,563\tWARNING algorithm_config.py:488 -- Cannot create DQNConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(DQN pid=33591)\u001b[0m 2023-08-16 17:54:03,563\tINFO algorithm_config.py:2503 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(DQN pid=33591)\u001b[0m 2023-08-16 17:54:03,657\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=33591)\u001b[0m 2023-08-16 17:54:03,660\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "== Status ==\n",
      "Current time: 2023-08-16 17:54:04 (running for 00:00:03.70)\n",
      "Memory usage on this node: 7.2/31.3 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1.0/16 CPUs, 0/1 GPUs, 0.0/15.59 GiB heap, 0.0/7.8 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(DQN pid=33591)\u001b[0m 2023-08-16 17:54:04,269\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(DQN pid=33591)\u001b[0m 2023-08-16 17:54:05,245\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
      "== Status ==\n",
      "Current time: 2023-08-16 17:54:10 (running for 00:00:09.68)\n",
      "Memory usage on this node: 7.2/31.3 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1.0/16 CPUs, 0/1 GPUs, 0.0/15.59 GiB heap, 0.0/7.8 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-08-16 17:54:17 (running for 00:00:17.25)\n",
      "Memory usage on this node: 7.2/31.3 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1.0/16 CPUs, 0/1 GPUs, 0.0/15.59 GiB heap, 0.0/7.8 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-08-16 17:54:25 (running for 00:00:24.77)\n",
      "Memory usage on this node: 7.3/31.3 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1.0/16 CPUs, 0/1 GPUs, 0.0/15.59 GiB heap, 0.0/7.8 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-08-16 17:54:33 (running for 00:00:32.44)\n",
      "Memory usage on this node: 7.3/31.3 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1.0/16 CPUs, 0/1 GPUs, 0.0/15.59 GiB heap, 0.0/7.8 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-08-16 17:54:40 (running for 00:00:40.19)\n",
      "Memory usage on this node: 7.6/31.3 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1.0/16 CPUs, 0/1 GPUs, 0.0/15.59 GiB heap, 0.0/7.8 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-08-16 17:54:48 (running for 00:00:47.96)\n",
      "Memory usage on this node: 7.6/31.3 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1.0/16 CPUs, 0/1 GPUs, 0.0/15.59 GiB heap, 0.0/7.8 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-08-16 17:54:56 (running for 00:00:55.79)\n",
      "Memory usage on this node: 7.8/31.3 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1.0/16 CPUs, 0/1 GPUs, 0.0/15.59 GiB heap, 0.0/7.8 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-08-16 17:55:04 (running for 00:01:03.48)\n",
      "Memory usage on this node: 7.7/31.3 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1.0/16 CPUs, 0/1 GPUs, 0.0/15.59 GiB heap, 0.0/7.8 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-08-16 17:55:11 (running for 00:01:11.06)\n",
      "Memory usage on this node: 7.7/31.3 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1.0/16 CPUs, 0/1 GPUs, 0.0/15.59 GiB heap, 0.0/7.8 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/default\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-08-16 17:55:14 (running for 00:01:13.69)\n",
      "Memory usage on this node: 7.7/31.3 GiB \n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/15.59 GiB heap, 0.0/7.8 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/default\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n",
      "2023-08-16 17:55:14,848\tINFO tune.py:762 -- Total run time: 74.33 seconds (73.68 seconds for the tuning loop).\n",
      "\n",
      "Your training finished.\n",
      "Best available checkpoint for each trial:\n",
      "  \u001b[35m/home/jim/ray_results/default/DQN_maze_gym_env.GymEnvironment_68671_00000_0_20\u001b[0m\n",
      "\u001b[35m23-08-16_17-54-00/\u001b[0m\u001b[95mcheckpoint_000010\u001b[0m\n",
      "\n",
      "You can now evaluate your trained algorithm from any checkpoint, e.g. by \n",
      "running:\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[32m  rllib evaluate \u001b[0m                                                            │\n",
      "│ \u001b[32m/home/jim/ray_results/default/DQN_maze_gym_env.GymEnvironment_68671_00000_0_\u001b[0m │\n",
      "│ \u001b[32m2023-08-16_17-54-00/checkpoint_000010 --algo DQN\u001b[0m                             │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! rllib train file maze.py --stop '{\"timesteps_total\": 10000}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dfc658",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "Try:\n",
    "rllib evaluate ~/ray_results/maze_env/<checkpoint>\\\n",
    " --algo DQN\\\n",
    " --env maze_gym_env.Environment\\\n",
    " --steps 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "702f69d7-fbea-44de-80ab-53ece7a84e82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/air/_internal/remote_storage.py:4: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import packaging\n",
      "/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.logging')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/tune/logger/tensorboardx.py:35: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  VALID_NP_HPARAMS = (np.bool8, np.float32, np.float64, np.int32, np.int64)\n",
      "/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if (distutils.version.LooseVersion(tf.__version__) <\n",
      "2023-08-16 18:00:32,086\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2023-08-16 18:00:32,851\tWARNING deprecation.py:47 -- DeprecationWarning: `algo = Algorithm(env='maze_gym_env.GymEnvironment', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('maze_gym_env.GymEnvironment').build()` instead. This will raise an error in the future!\n",
      "2023-08-16 18:00:32,851\tINFO algorithm_config.py:2503 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "2023-08-16 18:00:32,859\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2023-08-16 18:00:32,861\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/\u001b[0m\u001b[1;33mscripts.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m163\u001b[0m in \u001b[92mevaluate\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mray\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mrllib\u001b[0m \u001b[94mimport\u001b[0m evaluate \u001b[94mas\u001b[0m evaluate_module                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m163 \u001b[2m│   \u001b[0mevaluate_module.run(                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   \u001b[0mcheckpoint=checkpoint,                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m\u001b[2m│   │   \u001b[0malgo=algo,                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0menv=env,                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            algo = \u001b[33m'DQN'\u001b[0m                                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      checkpoint = \u001b[33m'/home/jim/ray_results/default/DQN_maze_gym_env.GymEn…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          config = \u001b[33m'\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[33m'\u001b[0m                                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             env = \u001b[94mNone\u001b[0m                                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        episodes = \u001b[94m0\u001b[0m                                                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m evaluate_module = \u001b[1m<\u001b[0m\u001b[1;95mmodule\u001b[0m\u001b[39m \u001b[0m\u001b[33m'ray.rllib.evaluate'\u001b[0m\u001b[39m from \u001b[0m                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   \u001b[33m'/home/jim/mambaforge/envs/ray/lib/python3.8/site-pac…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      local_mode = \u001b[94mFalse\u001b[0m                                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             out = \u001b[94mNone\u001b[0m                                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          render = \u001b[94mFalse\u001b[0m                                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       save_info = \u001b[94mFalse\u001b[0m                                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           steps = \u001b[94m100\u001b[0m                                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  track_progress = \u001b[94mFalse\u001b[0m                                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      use_shelve = \u001b[94mFalse\u001b[0m                                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/\u001b[0m\u001b[1;33mevaluate\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m250\u001b[0m in \u001b[92mrun\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m247 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m248 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Create the Algorithm from config.\u001b[0m                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m249 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mcls\u001b[0m = get_trainable_cls(algo)                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m250 \u001b[2m│   \u001b[0malgorithm = \u001b[96mcls\u001b[0m(env=env, config=config)                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m251 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m252 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Load state from checkpoint, if provided.\u001b[0m                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m253 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m checkpoint:                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              algo = \u001b[33m'DQN'\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        checkpoint = \u001b[33m'/home/jim/ray_results/default/DQN_maze_gym_env.Gym…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               cls = \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[33m'ray.rllib.algorithms.dqn.dqn.DQN'\u001b[0m\u001b[1m>\u001b[0m           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            config = \u001b[1m{\u001b[0m                                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'extra_python_environs_for_driver'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'extra_python_environs_for_worker'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'num_gpus'\u001b[0m: \u001b[94m0\u001b[0m,                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'num_cpus_per_worker'\u001b[0m: \u001b[94m1\u001b[0m,                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'num_gpus_per_worker'\u001b[0m: \u001b[94m0\u001b[0m,                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'_fake_gpus'\u001b[0m: \u001b[94mFalse\u001b[0m,                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'custom_resources_per_worker'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'placement_strategy'\u001b[0m: \u001b[33m'PACK'\u001b[0m,                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'eager_tracing'\u001b[0m: \u001b[94mFalse\u001b[0m,                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'eager_max_retraces'\u001b[0m: \u001b[94m20\u001b[0m,                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m...\u001b[0m +\u001b[94m113\u001b[0m                                         \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[1m}\u001b[0m                                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       config_args = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        config_dir = \u001b[33m'/home/jim/ray_results/default/DQN_maze_gym_env.Gym…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       config_path = \u001b[33m'/home/jim/ray_results/default/DQN_maze_gym_env.Gym…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               env = \u001b[33m'maze_gym_env.GymEnvironment'\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          episodes = \u001b[94m0\u001b[0m                                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m evaluation_config = \u001b[1m{\u001b[0m\u001b[33m'explore'\u001b[0m: \u001b[94mFalse\u001b[0m\u001b[1m}\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 f = \u001b[1m<\u001b[0m\u001b[1;95m_io.BufferedReader\u001b[0m\u001b[39m \u001b[0m                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[33mname\u001b[0m\u001b[39m=\u001b[0m\u001b[33m'/home/jim/ray_results/default/DQN_maze_gym_en…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        local_mode = \u001b[94mFalse\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               out = \u001b[94mNone\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            render = \u001b[94mFalse\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         save_info = \u001b[94mFalse\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             steps = \u001b[94m100\u001b[0m                                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m    track_progress = \u001b[94mFalse\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        use_shelve = \u001b[94mFalse\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/algorith\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mms/\u001b[0m\u001b[1;33malgorithm.py\u001b[0m:\u001b[94m441\u001b[0m in \u001b[92m__init__\u001b[0m                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 438 \u001b[0m\u001b[2m│   │   │   \u001b[0m}                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 439 \u001b[0m\u001b[2m│   │   \u001b[0m}                                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 440 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 441 \u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__init__\u001b[0m(                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 442 \u001b[0m\u001b[2m│   │   │   \u001b[0mconfig=config,                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 443 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogger_creator=logger_creator,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 444 \u001b[0m\u001b[2m│   │   │   \u001b[0m**kwargs,                                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 config = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.algorithms.dqn.dqn.DQNConfig\u001b[0m\u001b[39m object \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                          \u001b[39mat \u001b[0m\u001b[94m0x7ff9f0094ca0\u001b[0m\u001b[1m>\u001b[0m                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         default_config = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.algorithms.dqn.dqn.DQNConfig\u001b[0m\u001b[39m object \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                          \u001b[39mat \u001b[0m\u001b[94m0x7ff9f0094ca0\u001b[0m\u001b[1m>\u001b[0m                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m default_logger_creator = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m \u001b[0m                                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                          \u001b[39mAlgorithm.__init__.<locals>.default_logger_cre…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                          \u001b[39mat \u001b[0m\u001b[94m0x7ff9f0099dc0\u001b[0m\u001b[1m>\u001b[0m                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    env = \u001b[33m'maze_gym_env.GymEnvironment'\u001b[0m                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              env_descr = \u001b[33m'maze_gym_env.GymEnvironment'\u001b[0m                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 logdir = \u001b[33m'/home/jim/ray_results/DQN_maze_gym_env.GymEnv…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          logdir_prefix = \u001b[33m'DQN_maze_gym_env.GymEnvironment_2023-08-16_18…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         logger_creator = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m \u001b[0m                                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                          \u001b[39mAlgorithm.__init__.<locals>.default_logger_cre…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                          \u001b[39mat \u001b[0m\u001b[94m0x7ff9f0099dc0\u001b[0m\u001b[1m>\u001b[0m                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   self = DQN                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                timestr = \u001b[33m'2023-08-16_18-00-32'\u001b[0m                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/tune/trainable\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/\u001b[0m\u001b[1;33mtrainable.py\u001b[0m:\u001b[94m169\u001b[0m in \u001b[92m__init__\u001b[0m                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 166 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 167 \u001b[0m\u001b[2m│   │   \u001b[0mstart_time = time.time()                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 168 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._local_ip = ray.util.get_node_ip_address()               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 169 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.setup(copy.deepcopy(\u001b[96mself\u001b[0m.config))                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 170 \u001b[0m\u001b[2m│   │   \u001b[0msetup_time = time.time() - start_time                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 171 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m setup_time > SETUP_TIME_THRESHOLD:                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 172 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogger.info(                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                config = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.algorithms.dqn.dqn.DQNConfig\u001b[0m\u001b[39m object \u001b[0m  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mat \u001b[0m\u001b[94m0x7ff9f0094ca0\u001b[0m\u001b[1m>\u001b[0m                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         custom_syncer = \u001b[94mNone\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        logger_creator = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m \u001b[0m                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mAlgorithm.__init__.<locals>.default_logger_crea…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mat \u001b[0m\u001b[94m0x7ff9f0099dc0\u001b[0m\u001b[1m>\u001b[0m                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m remote_checkpoint_dir = \u001b[94mNone\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                  self = DQN                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            start_time = \u001b[94m1692223232.858475\u001b[0m                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           stderr_file = \u001b[94mNone\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           stdout_file = \u001b[94mNone\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          sync_timeout = \u001b[94mNone\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            trial_info = \u001b[94mNone\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/algorith\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mms/\u001b[0m\u001b[1;33malgorithm.py\u001b[0m:\u001b[94m566\u001b[0m in \u001b[92msetup\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 563 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m#   in each training iteration.\u001b[0m                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 564 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# This matches the behavior of using `build_trainer()`, w\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 565 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# has been deprecated.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 566 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.workers = WorkerSet(                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 567 \u001b[0m\u001b[2m│   │   │   │   \u001b[0menv_creator=\u001b[96mself\u001b[0m.env_creator,                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 568 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mvalidate_env=\u001b[96mself\u001b[0m.validate_env,                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 569 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdefault_policy_class=\u001b[96mself\u001b[0m.get_default_policy_class(\u001b[96mse\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            _init = \u001b[94mFalse\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           config = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.algorithms.dqn.dqn.DQNConfig\u001b[0m\u001b[39m object at \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[94m0x7ff9f001a130\u001b[0m\u001b[1m>\u001b[0m                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m input_evaluation = \u001b[94m-1\u001b[0m                                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        log_level = \u001b[33m'WARN'\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             self = DQN                                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluati\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mon/\u001b[0m\u001b[1;33mworker_set.py\u001b[0m:\u001b[94m169\u001b[0m in \u001b[92m__init__\u001b[0m                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m _setup:                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m169 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._setup(                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m170 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mvalidate_env=validate_env,                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m171 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mconfig=config,                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m172 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mnum_workers=num_workers,                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               _setup = \u001b[94mTrue\u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      AlgorithmConfig = \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[33m'ray.rllib.algorithms.algorithm_config.Algorithm…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               config = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.algorithms.dqn.dqn.DQNConfig\u001b[0m\u001b[39m object at\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[94m0x7ff9f0094ca0\u001b[0m\u001b[1m>\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m default_policy_class = \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[33m'ray.rllib.policy.tf_policy_template.DQNTFPolicy…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          env_creator = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m \u001b[0m                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mAlgorithm._get_env_id_and_creator.<locals>.env_c…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mat \u001b[0m\u001b[94m0x7ff9f0099c10\u001b[0m\u001b[1m>\u001b[0m                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         local_worker = \u001b[94mTrue\u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               logdir = \u001b[33m'/home/jim/ray_results/DQN_maze_gym_env.GymEnvir…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          num_workers = \u001b[94m0\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         policy_class = \u001b[94m-1\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 self = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.evaluation.worker_set.WorkerSet\u001b[0m\u001b[39m object\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mat \u001b[0m\u001b[94m0x7ff9f001a370\u001b[0m\u001b[1m>\u001b[0m                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       trainer_config = \u001b[94m-1\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         validate_env = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m Algorithm.validate_env at \u001b[0m              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[94m0x7ff9101feca0\u001b[0m\u001b[1m>\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           worker_cls = \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[33m'ray.rllib.evaluation.rollout_worker.RolloutWork…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluati\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mon/\u001b[0m\u001b[1;33mworker_set.py\u001b[0m:\u001b[94m259\u001b[0m in \u001b[92m_setup\u001b[0m                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m256 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m257 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Create a local worker, if needed.\u001b[0m                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m258 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m local_worker:                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m259 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._local_worker = \u001b[96mself\u001b[0m._make_worker(                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m260 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mcls\u001b[0m=RolloutWorker,                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m261 \u001b[0m\u001b[2m│   │   │   │   \u001b[0menv_creator=\u001b[96mself\u001b[0m._env_creator,                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m262 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mvalidate_env=validate_env,                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                config = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.algorithms.dqn.dqn.DQNConfig\u001b[0m\u001b[39m object \u001b[0m  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mat \u001b[0m\u001b[94m0x7ff9f0094ca0\u001b[0m\u001b[1m>\u001b[0m                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m local_tf_session_args = \u001b[1m{\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[2m│   \u001b[0m\u001b[33m'intra_op_parallelism_threads'\u001b[0m: \u001b[94m8\u001b[0m,           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[2m│   \u001b[0m\u001b[33m'inter_op_parallelism_threads'\u001b[0m: \u001b[94m8\u001b[0m,           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[2m│   \u001b[0m\u001b[33m'gpu_options'\u001b[0m: \u001b[1m{\u001b[0m\u001b[33m'allow_growth'\u001b[0m: \u001b[94mTrue\u001b[0m\u001b[1m}\u001b[0m,       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[2m│   \u001b[0m\u001b[33m'log_device_placement'\u001b[0m: \u001b[94mFalse\u001b[0m,               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[2m│   \u001b[0m\u001b[33m'device_count'\u001b[0m: \u001b[1m{\u001b[0m\u001b[33m'CPU'\u001b[0m: \u001b[94m1\u001b[0m\u001b[1m}\u001b[0m,                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[2m│   \u001b[0m\u001b[33m'allow_soft_placement'\u001b[0m: \u001b[94mTrue\u001b[0m                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[1m}\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          local_worker = \u001b[94mTrue\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           num_workers = \u001b[94m0\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                  self = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.evaluation.worker_set.WorkerSet\u001b[0m\u001b[39m \u001b[0m      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mobject at \u001b[0m\u001b[94m0x7ff9f001a370\u001b[0m\u001b[1m>\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                spaces = \u001b[94mNone\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          validate_env = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m Algorithm.validate_env at \u001b[0m             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[94m0x7ff9101feca0\u001b[0m\u001b[1m>\u001b[0m                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluati\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mon/\u001b[0m\u001b[1;33mworker_set.py\u001b[0m:\u001b[94m941\u001b[0m in \u001b[92m_make_worker\u001b[0m                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m938 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogger.debug(\u001b[33m\"\u001b[0m\u001b[33mCreating TF session \u001b[0m\u001b[33m{}\u001b[0m\u001b[33m\"\u001b[0m.format(config[\u001b[33m\"\u001b[0m\u001b[33mtf_se\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m939 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m tf1.Session(config=tf1.ConfigProto(**config[\u001b[33m\"\u001b[0m\u001b[33mtf_ses\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m940 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m941 \u001b[2m│   │   \u001b[0mworker = \u001b[96mcls\u001b[0m(                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m942 \u001b[0m\u001b[2m│   │   │   \u001b[0menv_creator=env_creator,                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m943 \u001b[0m\u001b[2m│   │   │   \u001b[0mvalidate_env=validate_env,                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m944 \u001b[0m\u001b[2m│   │   │   \u001b[0mdefault_policy_class=\u001b[96mself\u001b[0m._policy_class,                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              cls = \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[33m'ray.rllib.evaluation.rollout_worker.RolloutWorker'\u001b[0m\u001b[1m>\u001b[0m  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           config = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.algorithms.dqn.dqn.DQNConfig\u001b[0m\u001b[39m object at \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[94m0x7ff9effbec40\u001b[0m\u001b[1m>\u001b[0m                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      env_creator = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m \u001b[0m                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[39mAlgorithm._get_env_id_and_creator.<locals>.env_creat…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[39mat \u001b[0m\u001b[94m0x7ff9f0099c10\u001b[0m\u001b[1m>\u001b[0m                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      num_workers = \u001b[94m0\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m recreated_worker = \u001b[94mFalse\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             self = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.evaluation.worker_set.WorkerSet\u001b[0m\u001b[39m object at \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[94m0x7ff9f001a370\u001b[0m\u001b[1m>\u001b[0m                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  session_creator = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m \u001b[0m                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[39mWorkerSet._make_worker.<locals>.session_creator at \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[94m0x7ff9effab1f0\u001b[0m\u001b[1m>\u001b[0m                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           spaces = \u001b[94mNone\u001b[0m                                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     validate_env = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m Algorithm.validate_env at \u001b[0m\u001b[94m0x7ff9101feca0\u001b[0m\u001b[1m>\u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     worker_index = \u001b[94m0\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluati\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mon/\u001b[0m\u001b[1;33mrollout_worker.py\u001b[0m:\u001b[94m712\u001b[0m in \u001b[92m__init__\u001b[0m                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 709 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 710 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.filters: Dict[PolicyID, Filter] = defaultdict(NoFilter)  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 711 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 712 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._build_policy_map(                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 713 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.policy_dict,                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 714 \u001b[0m\u001b[2m│   │   │   \u001b[0mconfig=\u001b[96mself\u001b[0m.config,                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 715 \u001b[0m\u001b[2m│   │   │   \u001b[0msession_creator=tf_session_creator,                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   AlgorithmConfig = \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                                     \u001b[33m'ray.rllib.algorithms.algorithm_con…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        batch_mode = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         callbacks = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      clip_actions = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      clip_rewards = \u001b[94mNone\u001b[0m                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             compress_observations = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                            config = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.algorithms.dqn.dqn.DQNCo…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                                     \u001b[39mobject at \u001b[0m\u001b[94m0x7ff9effbec40\u001b[0m\u001b[1m>\u001b[0m            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  configured_rollout_fragment_length \u001b[94m1\u001b[0m                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                                   =                                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    count_steps_by = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    dataset_shards = \u001b[94mNone\u001b[0m                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              default_policy_class = \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                                     \u001b[33m'ray.rllib.policy.tf_policy_templat…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                           devices = \u001b[1m[\u001b[0m\u001b[33m'/physical_device:GPU:0'\u001b[0m\u001b[1m]\u001b[0m           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              disable_env_checking = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        env_config = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                       env_context = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                       env_creator = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m \u001b[0m                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                                     \u001b[39mAlgorithm._get_env_id_and_creator.<…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                                     \u001b[39mat \u001b[0m\u001b[94m0x7ff9f0099c10\u001b[0m\u001b[1m>\u001b[0m                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   episode_horizon = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             extra_python_environs = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      fake_sampler = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      gen_rollouts = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m \u001b[0m                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                                     \u001b[39mRolloutWorker.__init__.<locals>.gen…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                                     \u001b[39mat \u001b[0m\u001b[94m0x7ff9effc4040\u001b[0m\u001b[1m>\u001b[0m                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     input_creator = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                           log_dir = \u001b[33m'/home/jim/ray_results/DQN_maze_gym…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         log_level = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      model_config = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    no_done_at_end = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 normalize_actions = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                          num_envs = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                          num_gpus = \u001b[94m0\u001b[0m                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                       num_workers = \u001b[94m0\u001b[0m                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    observation_fn = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    output_creator = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 policies_to_train = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                            policy = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     policy_config = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 policy_mapping_fn = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                       policy_spec = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 preprocessor_pref = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                  recreated_worker = \u001b[94mFalse\u001b[0m                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          remote_env_batch_wait_ms = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                remote_worker_envs = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           rollout_fragment_length = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      sample_async = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                              seed = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                              self = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.evaluation.rollout_worke…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                                     \u001b[39mobject at \u001b[0m\u001b[94m0x7ff9effbebe0\u001b[0m\u001b[1m>\u001b[0m            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      soft_horizon = \u001b[94m-1\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                            spaces = \u001b[94mNone\u001b[0m                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                tf_session_creator = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m \u001b[0m                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                                     \u001b[39mWorkerSet._make_worker.<locals>.ses…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                                     \u001b[39mat \u001b[0m\u001b[94m0x7ff9effab1f0\u001b[0m\u001b[1m>\u001b[0m                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      validate_env = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m Algorithm.validate_env at \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                                     \u001b[94m0x7ff9101feca0\u001b[0m\u001b[1m>\u001b[0m                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      worker_index = \u001b[94m0\u001b[0m                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                              wrap = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m \u001b[0m                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                                     \u001b[39mRolloutWorker.__init__.<locals>.wrap\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                                     \u001b[39mat \u001b[0m\u001b[94m0x7ff9effc40d0\u001b[0m\u001b[1m>\u001b[0m                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluati\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mon/\u001b[0m\u001b[1;33mrollout_worker.py\u001b[0m:\u001b[94m1970\u001b[0m in \u001b[92m_build_policy_map\u001b[0m                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1967 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.policy_map.insert_policy(name, policy)           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1968 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1969 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Create the actual policy object.\u001b[0m                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1970 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.policy_map.create_policy(                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1971 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mname,                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1972 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpolicy_spec.policy_class,                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1973 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mobs_space,                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m AlgorithmConfig = \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   \u001b[33m'ray.rllib.algorithms.algorithm_config.AlgorithmConfi…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          config = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.algorithms.dqn.dqn.DQNConfig\u001b[0m\u001b[39m object at \u001b[0m     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   \u001b[94m0x7ff9effbec40\u001b[0m\u001b[1m>\u001b[0m                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     merged_conf = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.algorithms.dqn.dqn.DQNConfig\u001b[0m\u001b[39m object at \u001b[0m     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   \u001b[94m0x7ff9effcba90\u001b[0m\u001b[1m>\u001b[0m                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            name = \u001b[33m'default_policy'\u001b[0m                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       obs_space = \u001b[1;35mBox\u001b[0m\u001b[1m(\u001b[0m\u001b[94m-1.0\u001b[0m, \u001b[94m1.0\u001b[0m, \u001b[1m(\u001b[0m\u001b[94m25\u001b[0m,\u001b[1m)\u001b[0m, float32\u001b[1m)\u001b[0m                         \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          policy = \u001b[94mNone\u001b[0m                                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     policy_dict = \u001b[1m{\u001b[0m                                                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   \u001b[2m│   \u001b[0m\u001b[33m'default_policy'\u001b[0m:                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.policy.policy.PolicySpec\u001b[0m\u001b[39m object at \u001b[0m         \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   \u001b[94m0x7ff9effcb9d0\u001b[0m\u001b[1m>\u001b[0m                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   \u001b[1m}\u001b[0m                                                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     policy_spec = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.policy.policy.PolicySpec\u001b[0m\u001b[39m object at \u001b[0m         \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   \u001b[94m0x7ff9effcb9d0\u001b[0m\u001b[1m>\u001b[0m                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m    preprocessor = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.models.preprocessors.OneHotPreprocessor\u001b[0m\u001b[39m \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   \u001b[39mobject at \u001b[0m\u001b[94m0x7ff9effcba30\u001b[0m\u001b[1m>\u001b[0m                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            seed = \u001b[94mNone\u001b[0m                                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            self = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.evaluation.rollout_worker.RolloutWorker\u001b[0m\u001b[39m \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   \u001b[39mobject at \u001b[0m\u001b[94m0x7ff9effbebe0\u001b[0m\u001b[1m>\u001b[0m                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m session_creator = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m \u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   \u001b[39mWorkerSet._make_worker.<locals>.session_creator at \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   \u001b[94m0x7ff9effab1f0\u001b[0m\u001b[1m>\u001b[0m                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/policy/\u001b[0m\u001b[1;33mp\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33molicy_map.py\u001b[0m:\u001b[94m146\u001b[0m in \u001b[92mcreate_policy\u001b[0m                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m144 \u001b[0m\u001b[2m│   │   \u001b[0m_class = get_tf_eager_cls_if_necessary(policy_cls, merged_conf \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m145 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m146 \u001b[2m│   │   \u001b[0mpolicy = create_policy_for_framework(                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m147 \u001b[0m\u001b[2m│   │   │   \u001b[0mpolicy_id,                                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m148 \u001b[0m\u001b[2m│   │   │   \u001b[0m_class,                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m149 \u001b[0m\u001b[2m│   │   │   \u001b[0mmerged_config,                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            _class = \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[33m'ray.rllib.policy.tf_policy_template.DQNTFPolicy'\u001b[0m\u001b[1m>\u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      action_space = \u001b[1;35mDiscrete\u001b[0m\u001b[1m(\u001b[0m\u001b[94m4\u001b[0m\u001b[1m)\u001b[0m                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   config_override = \u001b[94mNone\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     merged_config = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.algorithms.dqn.dqn.DQNConfig\u001b[0m\u001b[39m object at \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[94m0x7ff9effcba90\u001b[0m\u001b[1m>\u001b[0m                                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m observation_space = \u001b[1;35mBox\u001b[0m\u001b[1m(\u001b[0m\u001b[94m-1.0\u001b[0m, \u001b[94m1.0\u001b[0m, \u001b[1m(\u001b[0m\u001b[94m25\u001b[0m,\u001b[1m)\u001b[0m, float32\u001b[1m)\u001b[0m                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        policy_cls = \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[33m'ray.rllib.policy.tf_policy_template.DQNTFPolicy'\u001b[0m\u001b[1m>\u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         policy_id = \u001b[33m'default_policy'\u001b[0m                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              self = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/utils/\u001b[0m\u001b[1;33mpo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mlicy.py\u001b[0m:\u001b[94m105\u001b[0m in \u001b[92mcreate_policy_for_framework\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m102 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m framework == \u001b[33m\"\u001b[0m\u001b[33mtf\u001b[0m\u001b[33m\"\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m103 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m tf1.Graph().as_default():                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m104 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m session_creator:                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m105 \u001b[2m│   │   │   │   │   \u001b[0msess = session_creator()                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0msess = tf1.Session(                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mconfig=tf1.ConfigProto(                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      action_space = \u001b[1;35mDiscrete\u001b[0m\u001b[1m(\u001b[0m\u001b[94m4\u001b[0m\u001b[1m)\u001b[0m                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   AlgorithmConfig = \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[33m'ray.rllib.algorithms.algorithm_config.AlgorithmCon…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         framework = \u001b[33m'tf'\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     merged_config = \u001b[1m{\u001b[0m                                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'extra_python_environs_for_driver'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'extra_python_environs_for_worker'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'num_gpus'\u001b[0m: \u001b[94m0\u001b[0m,                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'num_cpus_per_worker'\u001b[0m: \u001b[94m1\u001b[0m,                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'num_gpus_per_worker'\u001b[0m: \u001b[94m0\u001b[0m,                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'_fake_gpus'\u001b[0m: \u001b[94mFalse\u001b[0m,                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'custom_resources_per_worker'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'placement_strategy'\u001b[0m: \u001b[33m'PACK'\u001b[0m,                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'eager_tracing'\u001b[0m: \u001b[94mFalse\u001b[0m,                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m'eager_max_retraces'\u001b[0m: \u001b[94m20\u001b[0m,                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[2m│   \u001b[0m\u001b[33m...\u001b[0m +\u001b[94m114\u001b[0m                                         \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[1m}\u001b[0m                                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m observation_space = \u001b[1;35mBox\u001b[0m\u001b[1m(\u001b[0m\u001b[94m-1.0\u001b[0m, \u001b[94m1.0\u001b[0m, \u001b[1m(\u001b[0m\u001b[94m25\u001b[0m,\u001b[1m)\u001b[0m, float32\u001b[1m)\u001b[0m                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      policy_class = \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[33m'ray.rllib.policy.tf_policy_template.DQNTFPolicy'\u001b[0m\u001b[1m>\u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         policy_id = \u001b[33m'default_policy'\u001b[0m                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              seed = \u001b[94mNone\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   session_creator = \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m \u001b[0m                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[39mWorkerSet._make_worker.<locals>.session_creator at \u001b[0m  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[94m0x7ff9effab1f0\u001b[0m\u001b[1m>\u001b[0m                                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         var_scope = \u001b[33m'default_policy'\u001b[0m                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      worker_index = \u001b[94m0\u001b[0m                                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluati\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mon/\u001b[0m\u001b[1;33mworker_set.py\u001b[0m:\u001b[94m939\u001b[0m in \u001b[92msession_creator\u001b[0m                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m936 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92msession_creator\u001b[0m():                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m937 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Default session creator function, if `tf_session_args` a\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m938 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogger.debug(\u001b[33m\"\u001b[0m\u001b[33mCreating TF session \u001b[0m\u001b[33m{}\u001b[0m\u001b[33m\"\u001b[0m.format(config[\u001b[33m\"\u001b[0m\u001b[33mtf_se\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m939 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m tf1.Session(config=tf1.ConfigProto(**config[\u001b[33m\"\u001b[0m\u001b[33mtf_ses\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m940 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m941 \u001b[0m\u001b[2m│   │   \u001b[0mworker = \u001b[96mcls\u001b[0m(                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m942 \u001b[0m\u001b[2m│   │   │   \u001b[0menv_creator=env_creator,                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m config = \u001b[1m<\u001b[0m\u001b[1;95mray.rllib.algorithms.dqn.dqn.DQNConfig\u001b[0m\u001b[39m object at \u001b[0m              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          \u001b[94m0x7ff9effbec40\u001b[0m\u001b[1m>\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/tensorflow/python/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mclient/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m1605\u001b[0m in \u001b[92m__init__\u001b[0m                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1602 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m[`ConfigProto`](https://www.tensorflow.org/code/tensorflow/co\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1603 \u001b[0m\u001b[2;33m│   │     \u001b[0m\u001b[33mprotocol buffer with configuration options for the session.\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1604 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1605 \u001b[2m│   \u001b[0m\u001b[96msuper\u001b[0m(Session, \u001b[96mself\u001b[0m).\u001b[92m__init__\u001b[0m(target, graph, config=config)       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1606 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# NOTE(mrry): Create these on first `__enter__` to avoid a refere\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1607 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mself\u001b[0m._default_graph_context_manager = \u001b[94mNone\u001b[0m                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1608 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mself\u001b[0m._default_session_context_manager = \u001b[94mNone\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m config = device_count \u001b[1m{\u001b[0m                                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          \u001b[2m  \u001b[0mkey: \u001b[33m\"CPU\"\u001b[0m                                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          \u001b[2m  \u001b[0mvalue: \u001b[94m1\u001b[0m                                                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          \u001b[1m}\u001b[0m                                                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          intra_op_parallelism_threads: \u001b[94m8\u001b[0m                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          inter_op_parallelism_threads: \u001b[94m8\u001b[0m                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          gpu_options \u001b[1m{\u001b[0m                                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          \u001b[2m  \u001b[0mallow_growth: true                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          \u001b[1m}\u001b[0m                                                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          allow_soft_placement: true                                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  graph = \u001b[94mNone\u001b[0m                                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   self = \u001b[1m<\u001b[0m\u001b[1;95mtensorflow.python.client.session.Session\u001b[0m\u001b[39m object at \u001b[0m            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          \u001b[94m0x7ff9effcbdf0\u001b[0m\u001b[1m>\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m target = \u001b[33m''\u001b[0m                                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/tensorflow/python/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mclient/\u001b[0m\u001b[1;33msession.py\u001b[0m:\u001b[94m713\u001b[0m in \u001b[92m__init__\u001b[0m                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 710 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 711 \u001b[0m\u001b[2m│     \u001b[0m\u001b[2m# pylint: disable=protected-access\u001b[0m                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 712 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m._graph._c_graph.get() \u001b[94mas\u001b[0m c_graph:                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 713 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._session = tf_session.TF_NewSessionRef(c_graph, opts)    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 714 \u001b[0m\u001b[2m│     \u001b[0m\u001b[2m# pylint: enable=protected-access\u001b[0m                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 715 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfinally\u001b[0m:                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 716 \u001b[0m\u001b[2m│     \u001b[0mtf_session.TF_DeleteSessionOptions(opts)                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m c_graph = PyGraph\u001b[1m<\u001b[0m\u001b[1;94m140711449872560\u001b[0m\u001b[1m>\u001b[0m                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  config = device_count \u001b[1m{\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           \u001b[2m  \u001b[0mkey: \u001b[33m\"CPU\"\u001b[0m                                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           \u001b[2m  \u001b[0mvalue: \u001b[94m1\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           \u001b[1m}\u001b[0m                                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           intra_op_parallelism_threads: \u001b[94m8\u001b[0m                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           inter_op_parallelism_threads: \u001b[94m8\u001b[0m                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           gpu_options \u001b[1m{\u001b[0m                                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           \u001b[2m  \u001b[0mallow_growth: true                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           \u001b[1m}\u001b[0m                                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           allow_soft_placement: true                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   graph = \u001b[94mNone\u001b[0m                                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m    opts = \u001b[1m<\u001b[0m\u001b[1;95mtensorflow.python.client._pywrap_tf_session.TF_SessionOptions\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           \u001b[39mobject at \u001b[0m\u001b[94m0x7ff9effd8870\u001b[0m\u001b[1m>\u001b[0m                                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m    self = \u001b[1m<\u001b[0m\u001b[1;95mtensorflow.python.client.session.Session\u001b[0m\u001b[39m object at \u001b[0m           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           \u001b[94m0x7ff9effcbdf0\u001b[0m\u001b[1m>\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  target = \u001b[33m''\u001b[0m                                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mInternalError: \u001b[0m\u001b[1;35mcudaGetDevice\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m failed. Status: cudaGetErrorString symbol not \n",
      "found.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! rllib evaluate ~/ray_results/default/DQN_maze_gym_env.GymEnvironment_68671_00000_0_2023-08-16_17-54-00/checkpoint_000010 --algo DQN --steps 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "965ee003",
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"_disable_action_flattening: false\\n_disable_execution_plan_api: true\\n_disable_preprocessor_api: false\\n_fake_gpus: false\\n_tf_policy_handles_more_than_one_loss: false\\nactions_in_input_normalized: false\\nadam_epsilon: 1.0e-08\\nalways_attach_evaluation_results: false\\nbatch_mode: truncate_episodes\\ncallbacks: <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>\\ncategorical_distribution_temperature: 1.0\\nclip_actions: false\\ncompress_observations: false\\ncreate_env_on_driver: false\\ncustom_resources_per_worker: {}\\ndisable_env_checking: false\\ndouble_q: true\\ndueling: true\\neager_max_retraces: 20\\neager_tracing: false\\nenable_async_evaluation: false\\nenable_connectors: false\\nenable_tf1_exec_eagerly: false\\nenv: <class 'maze_gym_env.GymEnvironment'>\\nenv_config: {}\\nevaluation_config:\\n  explore: false\\nevaluation_duration: 10\\nevaluation_duration_unit: episodes\\nevaluation_num_workers: 0\\nevaluation_parallel_to_training: false\\nevaluation_sample_timeout_s: 180.0\\nexploration_config:\\n  epsilon_timesteps: 10000\\n  final_epsilon: 0.02\\n  initial_epsilon: 1.0\\n  type: EpsilonGreedy\\nexplore: true\\nexport_native_model_files: false\\nextra_python_environs_for_driver: {}\\nextra_python_environs_for_worker: {}\\nfake_sampler: false\\nframework: tf\\ngamma: 0.99\\ngrad_clip: 40\\nhiddens:\\n- 256\\nignore_worker_failures: false\\nin_evaluation: false\\ninput: sampler\\ninput_config: {}\\nkeep_per_episode_custom_metrics: false\\nlocal_tf_session_args:\\n  inter_op_parallelism_threads: 8\\n  intra_op_parallelism_threads: 8\\nlog_level: WARN\\nlog_sys_usage: true\\nlr: 0.0005\\nmax_requests_in_flight_per_sampler_worker: 2\\nmetrics_episode_collection_timeout_s: 60.0\\nmetrics_num_episodes_for_smoothing: 100\\nmin_sample_timesteps_per_iteration: 1000\\nmin_train_timesteps_per_iteration: 0\\nmodel:\\n  _disable_action_flattening: false\\n  _disable_preprocessor_api: false\\n  _time_major: false\\n  _use_default_native_models: false\\n  attention_dim: 64\\n  attention_head_dim: 32\\n  attention_init_gru_gate_bias: 2.0\\n  attention_memory_inference: 50\\n  attention_memory_training: 50\\n  attention_num_heads: 1\\n  attention_num_transformer_units: 1\\n  attention_position_wise_mlp_dim: 32\\n  attention_use_n_prev_actions: 0\\n  attention_use_n_prev_rewards: 0\\n  conv_activation: relu\\n  conv_filters: null\\n  custom_action_dist: null\\n  custom_model: null\\n  custom_model_config: {}\\n  custom_preprocessor: null\\n  dim: 84\\n  fcnet_activation: tanh\\n  fcnet_hiddens:\\n  - 256\\n  - 256\\n  framestack: true\\n  free_log_std: false\\n  grayscale: false\\n  lstm_cell_size: 256\\n  lstm_use_prev_action: false\\n  lstm_use_prev_action_reward: -1\\n  lstm_use_prev_reward: false\\n  max_seq_len: 20\\n  no_final_linear: false\\n  post_fcnet_activation: relu\\n  post_fcnet_hiddens: []\\n  use_attention: false\\n  use_lstm: false\\n  vf_share_layers: true\\n  zero_mean: true\\nmultiagent:\\n  count_steps_by: env_steps\\n  observation_fn: null\\n  policies:\\n    default_policy: <ray.rllib.policy.policy.PolicySpec object at 0x7f591df00ee0>\\n  policies_to_train: null\\n  policy_map_cache: null\\n  policy_map_capacity: 100\\n  policy_mapping_fn: <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7f5bcb6b8a60>\\nn_step: 1\\nno_done_at_end: false\\nnoisy: false\\nnormalize_actions: true\\nnum_atoms: 1\\nnum_consecutive_worker_failures_tolerance: 100\\nnum_cpus_for_driver: 1\\nnum_cpus_per_worker: 1\\nnum_envs_per_worker: 1\\nnum_gpus: 0\\nnum_gpus_per_worker: 0\\nnum_steps_sampled_before_learning_starts: 1000\\nnum_workers: 0\\nobservation_filter: NoFilter\\noff_policy_estimation_methods: {}\\noffline_sampling: false\\nope_split_batch_by_episode: true\\noptimizer: {}\\noutput_compress_columns:\\n- obs\\n- new_obs\\noutput_config: {}\\noutput_max_file_size: 67108864\\nplacement_strategy: PACK\\npostprocess_inputs: false\\npreprocessor_pref: deepmind\\nrecreate_failed_workers: false\\nremote_env_batch_wait_ms: 0\\nremote_worker_envs: false\\nrender_env: false\\nreplay_buffer_config:\\n  capacity: 50000\\n  prioritized_replay: -1\\n  prioritized_replay_alpha: 0.6\\n  prioritized_replay_beta: 0.4\\n  prioritized_replay_eps: 1.0e-06\\n  replay_sequence_length: 1\\n  type: MultiAgentPrioritizedReplayBuffer\\n  worker_side_prioritization: false\\nrestart_failed_sub_environments: false\\nrollout_fragment_length: auto\\nsample_async: false\\nsample_collector: <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>\\nshuffle_buffer_size: 0\\nsigma0: 0.5\\nsimple_optimizer: -1\\nsoft_horizon: false\\nstore_buffer_in_checkpoints: false\\nsync_filters_on_rollout_workers_timeout_s: 60.0\\nsynchronize_filters: true\\ntarget_network_update_freq: 500\\ntau: 1.0\\ntd_error_loss_fn: huber\\ntf_session_args:\\n  allow_soft_placement: true\\n  device_count:\\n    CPU: 1\\n  gpu_options:\\n    allow_growth: true\\n  inter_op_parallelism_threads: 2\\n  intra_op_parallelism_threads: 2\\n  log_device_placement: false\\ntrain_batch_size: 32\\nv_max: 10.0\\nv_min: -10.0\\nvalidate_workers_after_construction: true\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.tune.logger import pretty_print\n",
    "from maze_gym_env import GymEnvironment\n",
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "\n",
    "config = (DQNConfig().environment(GymEnvironment)\n",
    "          .rollouts())\n",
    "\n",
    "pretty_print(config.to_dict())\n",
    "\n",
    "# algo = config.build()\n",
    "\n",
    "# for i in range(10):\n",
    "#     result = algo.train()\n",
    "\n",
    "# print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14ba20ee-27ff-49c5-9536-d7a4195a9279",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "cudaGetDevice() failed. Status: cudaGetErrorString symbol not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m algo \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# for i in range(10):\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#     result = algo.train()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(pretty_print(result))\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm_config.py:746\u001b[0m, in \u001b[0;36mAlgorithmConfig.build\u001b[0;34m(self, env, logger_creator, use_copy)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgo_class, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    744\u001b[0m     algo_class \u001b[38;5;241m=\u001b[39m get_trainable_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgo_class)\n\u001b[0;32m--> 746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgo_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_copy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py:441\u001b[0m, in \u001b[0;36mAlgorithm.__init__\u001b[0;34m(self, config, env, logger_creator, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# Initialize common evaluation_metrics to nan, before they become\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# available. We want to make sure the metrics are always present\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# (although their values may be nan), so that Tune does not complain\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# when we use these as stopping criteria.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisode_reward_max\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mnan,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    438\u001b[0m     }\n\u001b[1;32m    439\u001b[0m }\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# Check, whether `training_iteration` is still a tune.Trainable property\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# and has not been overridden by the user in the attempt to implement the\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# algos logic (this should be done now inside `training_step`).\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/ray/lib/python3.8/site-packages/ray/tune/trainable/trainable.py:169\u001b[0m, in \u001b[0;36mTrainable.__init__\u001b[0;34m(self, config, logger_creator, remote_checkpoint_dir, custom_syncer, sync_timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_ip \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mget_node_ip_address()\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m setup_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m setup_time \u001b[38;5;241m>\u001b[39m SETUP_TIME_THRESHOLD:\n",
      "File \u001b[0;32m~/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py:566\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# Only if user did not override `_init()`:\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;66;03m# - Create rollout workers here automatically.\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;66;03m# - Run the execution plan to create the local iterator to `next()`\u001b[39;00m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;66;03m#   in each training iteration.\u001b[39;00m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;66;03m# This matches the behavior of using `build_trainer()`, which\u001b[39;00m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;66;03m# has been deprecated.\u001b[39;00m\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers \u001b[38;5;241m=\u001b[39m \u001b[43mWorkerSet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_policy_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_policy_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_workers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# TODO (avnishn): Remove the execution plan API by q1 2023\u001b[39;00m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;66;03m# Function defining one single training iteration's behavior.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_disable_execution_plan_api\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;66;03m# Ensure remote workers are initially in sync with the local worker.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py:169\u001b[0m, in \u001b[0;36mWorkerSet.__init__\u001b[0;34m(self, env_creator, validate_env, default_policy_class, config, num_workers, local_worker, logdir, _setup, policy_class, trainer_config)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _setup:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# WorkerSet creation possibly fails, if some (remote) workers cannot\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# be initialized properly (due to some errors in the RolloutWorker's\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# constructor).\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m RayActorError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;66;03m# In case of an actor (remote worker) init failure, the remote worker\u001b[39;00m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;66;03m# may still exist and will be accessible, however, e.g. calling\u001b[39;00m\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;66;03m# its `sample.remote()` would result in strange \"property not found\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;66;03m# errors.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py:259\u001b[0m, in \u001b[0;36mWorkerSet._setup\u001b[0;34m(self, validate_env, config, num_workers, local_worker)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Create a local worker, if needed.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_worker:\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_worker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRolloutWorker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworker_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_local_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py:941\u001b[0m, in \u001b[0;36mWorkerSet._make_worker\u001b[0;34m(self, cls, env_creator, validate_env, worker_index, num_workers, recreated_worker, config, spaces)\u001b[0m\n\u001b[1;32m    938\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating TF session \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_session_args\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf1\u001b[38;5;241m.\u001b[39mSession(config\u001b[38;5;241m=\u001b[39mtf1\u001b[38;5;241m.\u001b[39mConfigProto(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_session_args\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m--> 941\u001b[0m worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_policy_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_policy_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf_session_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msession_creator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf_session_args\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworker_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecreated_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecreated_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ds_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m worker\n",
      "File \u001b[0;32m~/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py:712\u001b[0m, in \u001b[0;36mRolloutWorker.__init__\u001b[0;34m(self, env_creator, validate_env, tf_session_creator, config, worker_index, num_workers, recreated_worker, log_dir, spaces, default_policy_class, dataset_shards, policy_config, input_creator, output_creator, rollout_fragment_length, count_steps_by, batch_mode, episode_horizon, preprocessor_pref, sample_async, compress_observations, num_envs, observation_fn, clip_rewards, normalize_actions, clip_actions, env_config, model_config, remote_worker_envs, remote_env_batch_wait_ms, soft_horizon, no_done_at_end, fake_sampler, seed, log_level, callbacks, disable_env_checking, policy_spec, policy_mapping_fn, policies_to_train, extra_python_environs, policy)\u001b[0m\n\u001b[1;32m    703\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are running ray with `local_mode=True`, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    705\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigured \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_gpus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GPUs to be used! In local mode, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolicies are placed on the CPU and the `num_gpus` setting \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    708\u001b[0m     )\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters: Dict[PolicyID, Filter] \u001b[38;5;241m=\u001b[39m defaultdict(NoFilter)\n\u001b[0;32m--> 712\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_policy_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_session_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;66;03m# Update Policy's view requirements from Model, only if Policy directly\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;66;03m# inherited from base `Policy` class. At this point here, the Policy\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;66;03m# must have it's Model (if any) defined and ready to output an initial\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pol \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_map\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py:1970\u001b[0m, in \u001b[0;36mRolloutWorker._build_policy_map\u001b[0;34m(self, policy_dict, config, policy, session_creator, seed)\u001b[0m\n\u001b[1;32m   1967\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_map\u001b[38;5;241m.\u001b[39minsert_policy(name, policy)\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1969\u001b[0m     \u001b[38;5;66;03m# Create the actual policy object.\u001b[39;00m\n\u001b[0;32m-> 1970\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_policy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobs_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmerged_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_conf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1979\u001b[0m new_policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_map[name]\n\u001b[1;32m   1980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merged_conf\u001b[38;5;241m.\u001b[39menable_connectors:\n",
      "File \u001b[0;32m~/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py:146\u001b[0m, in \u001b[0;36mPolicyMap.create_policy\u001b[0;34m(self, policy_id, policy_cls, observation_space, action_space, config_override, merged_config)\u001b[0m\n\u001b[1;32m    140\u001b[0m     deprecation_warning(\n\u001b[1;32m    141\u001b[0m         old\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolicyMap.create_policy(config_override=..)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    142\u001b[0m         error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m _class \u001b[38;5;241m=\u001b[39m get_tf_eager_cls_if_necessary(policy_cls, merged_config)\n\u001b[0;32m--> 146\u001b[0m policy \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_policy_for_framework\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmerged_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworker_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minsert_policy(policy_id, policy)\n",
      "File \u001b[0;32m~/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/utils/policy.py:105\u001b[0m, in \u001b[0;36mcreate_policy_for_framework\u001b[0;34m(policy_id, policy_class, merged_config, observation_space, action_space, worker_index, session_creator, seed)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf1\u001b[38;5;241m.\u001b[39mGraph()\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m session_creator:\n\u001b[0;32m--> 105\u001b[0m         sess \u001b[38;5;241m=\u001b[39m \u001b[43msession_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m         sess \u001b[38;5;241m=\u001b[39m tf1\u001b[38;5;241m.\u001b[39mSession(\n\u001b[1;32m    108\u001b[0m             config\u001b[38;5;241m=\u001b[39mtf1\u001b[38;5;241m.\u001b[39mConfigProto(\n\u001b[1;32m    109\u001b[0m                 gpu_options\u001b[38;5;241m=\u001b[39mtf1\u001b[38;5;241m.\u001b[39mGPUOptions(allow_growth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    110\u001b[0m             )\n\u001b[1;32m    111\u001b[0m         )\n",
      "File \u001b[0;32m~/mambaforge/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py:939\u001b[0m, in \u001b[0;36mWorkerSet._make_worker.<locals>.session_creator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msession_creator\u001b[39m():\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;66;03m# Default session creator function, if `tf_session_args` are provided.\u001b[39;00m\n\u001b[1;32m    938\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating TF session \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_session_args\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m--> 939\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConfigProto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf_session_args\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/ray/lib/python3.8/site-packages/tensorflow/python/client/session.py:1605\u001b[0m, in \u001b[0;36mSession.__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new TensorFlow session.\u001b[39;00m\n\u001b[1;32m   1586\u001b[0m \n\u001b[1;32m   1587\u001b[0m \u001b[38;5;124;03m  If no `graph` argument is specified when constructing the session,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;124;03m        protocol buffer with configuration options for the session.\u001b[39;00m\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1605\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1606\u001b[0m   \u001b[38;5;66;03m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m   1607\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_graph_context_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/ray/lib/python3.8/site-packages/tensorflow/python/client/session.py:713\u001b[0m, in \u001b[0;36mBaseSession.__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    711\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    712\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39m_c_graph\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mas\u001b[39;00m c_graph:\n\u001b[0;32m--> 713\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_NewSessionRef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m   tf_session\u001b[38;5;241m.\u001b[39mTF_DeleteSessionOptions(opts)\n",
      "\u001b[0;31mInternalError\u001b[0m: cudaGetDevice() failed. Status: cudaGetErrorString symbol not found."
     ]
    }
   ],
   "source": [
    "algo = config.build()\n",
    "\n",
    "# for i in range(10):\n",
    "#     result = algo.train()\n",
    "\n",
    "# print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "283bf0f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Algorithm\n\u001b[0;32m----> 4\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(checkpoint)\n\u001b[1;32m      7\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m algo\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'algo' is not defined"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "\n",
    "\n",
    "checkpoint = algo.save()\n",
    "print(checkpoint)\n",
    "\n",
    "evaluation = algo.evaluate()\n",
    "print(pretty_print(evaluation))\n",
    "\n",
    "algo.stop()\n",
    "restored_algo = Algorithm.from_checkpoint(checkpoint)\n",
    "\n",
    "algo = restored_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3c637",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "env = GymEnvironment()\n",
    "done = False\n",
    "total_reward = 0\n",
    "observations = env.reset()\n",
    "\n",
    "while not done:\n",
    "    action = algo.compute_single_action(observations)\n",
    "    observations, reward, done, info = env.step(action)\n",
    "    total_reward += reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = algo.compute_actions(\n",
    "    {\"obs_1\": observations, \"obs_2\": observations}\n",
    ")\n",
    "print(action)\n",
    "# {'obs_1': 0, 'obs_2': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d2c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = algo.get_policy()\n",
    "print(policy.get_weights())\n",
    "\n",
    "model = policy.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83366455",
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = algo.workers\n",
    "workers.foreach_worker(\n",
    "    lambda remote_trainer: remote_trainer.get_policy().get_weights()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a539340",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from ray.rllib.models.preprocessors import get_preprocessor\n",
    "\n",
    "\n",
    "env = GymEnvironment()\n",
    "obs_space = env.observation_space\n",
    "preprocessor = get_preprocessor(obs_space)(obs_space)\n",
    "\n",
    "observations = env.reset()\n",
    "transformed = preprocessor.transform(observations).reshape(1, -1)\n",
    "\n",
    "model_output, _ = model({\"obs\": transformed})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f47a55f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "q_values = model.get_q_value_distributions(model_output)\n",
    "print(q_values)\n",
    "\n",
    "action_distribution = policy.dist_class(model_output, model)\n",
    "sample = action_distribution.sample()\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dc4ca5",
   "metadata": {},
   "source": [
    "\n",
    "![RLlib Environments](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_04/rllib_envs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081e6a5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from gym.spaces import Discrete\n",
    "import os\n",
    "\n",
    "\n",
    "class MultiAgentMaze(MultiAgentEnv):\n",
    "\n",
    "    def __init__(self,  *args, **kwargs):\n",
    "        self.action_space = Discrete(4)\n",
    "        self.observation_space = Discrete(5*5)\n",
    "        self.agents = {1: (4, 0), 2: (0, 4)}\n",
    "        self.goal = (4, 4)\n",
    "        self.info = {1: {'obs': self.agents[1]}, 2: {'obs': self.agents[2]}}\n",
    "\n",
    "    def reset(self):\n",
    "        self.agents = {1: (4, 0), 2: (0, 4)}\n",
    "\n",
    "        return {1: self.get_observation(1), 2: self.get_observation(2)}\n",
    "\n",
    "    def get_observation(self, agent_id):\n",
    "        seeker = self.agents[agent_id]\n",
    "        return 5 * seeker[0] + seeker[1]\n",
    "\n",
    "    def get_reward(self, agent_id):\n",
    "        return 1 if self.agents[agent_id] == self.goal else 0\n",
    "\n",
    "    def is_done(self, agent_id):\n",
    "        return self.agents[agent_id] == self.goal\n",
    "\n",
    "    def step(self, action):\n",
    "        agent_ids = action.keys()\n",
    "\n",
    "        for agent_id in agent_ids:\n",
    "            seeker = self.agents[agent_id]\n",
    "            if action[agent_id] == 0:  # move down\n",
    "                seeker = (min(seeker[0] + 1, 4), seeker[1])\n",
    "            elif action[agent_id] == 1:  # move left\n",
    "                seeker = (seeker[0], max(seeker[1] - 1, 0))\n",
    "            elif action[agent_id] == 2:  # move up\n",
    "                seeker = (max(seeker[0] - 1, 0), seeker[1])\n",
    "            elif action[agent_id] == 3:  # move right\n",
    "                seeker = (seeker[0], min(seeker[1] + 1, 4))\n",
    "            else:\n",
    "                raise ValueError(\"Invalid action\")\n",
    "            self.agents[agent_id] = seeker\n",
    "\n",
    "        observations = {i: self.get_observation(i) for i in agent_ids}\n",
    "        rewards = {i: self.get_reward(i) for i in agent_ids}\n",
    "        done = {i: self.is_done(i) for i in agent_ids}\n",
    "\n",
    "        done[\"__all__\"] = all(done.values())\n",
    "\n",
    "        return observations, rewards, done, self.info\n",
    "\n",
    "    def render(self, *args, **kwargs):\n",
    "        \"\"\"We override this method here so clear the output in Jupyter notebooks.\n",
    "        The previous implementation works well in the terminal, but does not clear\n",
    "        the screen in interactive environments.\n",
    "        \"\"\"\n",
    "        os.system('cls' if os.name == 'nt' else 'clear')\n",
    "        try:\n",
    "            from IPython.display import clear_output\n",
    "            clear_output(wait=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "        grid = [['| ' for _ in range(5)] + [\"|\\n\"] for _ in range(5)]\n",
    "        grid[self.goal[0]][self.goal[1]] = '|G'\n",
    "        grid[self.agents[1][0]][self.agents[1][1]] = '|1'\n",
    "        grid[self.agents[2][0]][self.agents[2][1]] = '|2'\n",
    "        grid[self.agents[2][0]][self.agents[2][1]] = '|2'\n",
    "        print(''.join([''.join(grid_row) for grid_row in grid]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3057fa",
   "metadata": {},
   "source": [
    "![RLlib Mapping Envs](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_04/mapping_envs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74fd5b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "env = MultiAgentMaze()\n",
    "\n",
    "while True:\n",
    "    obs, rew, done, info = env.step(\n",
    "        {1: env.action_space.sample(), 2: env.action_space.sample()}\n",
    "    )\n",
    "    time.sleep(0.1)\n",
    "    env.render()\n",
    "    if any(done.values()):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417642b6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "\n",
    "simple_trainer = DQNConfig().environment(env=MultiAgentMaze).build()\n",
    "simple_trainer.train()\n",
    "\n",
    "algo = DQNConfig()\\\n",
    "    .environment(env=MultiAgentMaze)\\\n",
    "    .multi_agent(\n",
    "        policies={\n",
    "            \"policy_1\": (\n",
    "                None, env.observation_space, env.action_space, {\"gamma\": 0.80}\n",
    "            ),\n",
    "            \"policy_2\": (\n",
    "                None, env.observation_space, env.action_space, {\"gamma\": 0.95}\n",
    "            ),\n",
    "        },\n",
    "        policy_mapping_fn = lambda agent_id: f\"policy_{agent_id}\",\n",
    "    ).build()\n",
    "\n",
    "print(algo.train())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65341b",
   "metadata": {},
   "source": [
    "![RLlib External Envs](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_04/rllib_external.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b4d78",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from gym.spaces import Discrete\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "class AdvancedEnv(GymEnvironment):\n",
    "\n",
    "    def __init__(self, seeker=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.maze_len = 11\n",
    "        self.action_space = Discrete(4)\n",
    "        self.observation_space = Discrete(self.maze_len * self.maze_len)\n",
    "\n",
    "        if seeker:\n",
    "            assert 0 <= seeker[0] < self.maze_len and \\\n",
    "                   0 <= seeker[1] < self.maze_len\n",
    "            self.seeker = seeker\n",
    "        else:\n",
    "            self.reset()\n",
    "\n",
    "        self.goal = (self.maze_len-1, self.maze_len-1)\n",
    "        self.info = {'seeker': self.seeker, 'goal': self.goal}\n",
    "\n",
    "        self.punish_states = [\n",
    "            (i, j) for i in range(self.maze_len) for j in range(self.maze_len)\n",
    "            if i % 2 == 1 and j % 2 == 0\n",
    "        ]\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset seeker position randomly, return observations.\"\"\"\n",
    "        self.seeker = (\n",
    "            random.randint(0, self.maze_len - 1),\n",
    "            random.randint(0, self.maze_len - 1)\n",
    "        )\n",
    "        return self.get_observation()\n",
    "\n",
    "    def get_observation(self):\n",
    "        \"\"\"Encode the seeker position as integer\"\"\"\n",
    "        return self.maze_len * self.seeker[0] + self.seeker[1]\n",
    "\n",
    "    def get_reward(self):\n",
    "        \"\"\"Reward finding the goal and punish forbidden states\"\"\"\n",
    "        reward = -1 if self.seeker in self.punish_states else 0\n",
    "        reward += 5 if self.seeker == self.goal else 0\n",
    "        return reward\n",
    "\n",
    "    def render(self, *args, **kwargs):\n",
    "        \"\"\"We override this method here so clear the output in Jupyter notebooks.\n",
    "        The previous implementation works well in the terminal, but does not clear\n",
    "        the screen in interactive environments.\n",
    "        \"\"\"\n",
    "        os.system('cls' if os.name == 'nt' else 'clear')\n",
    "        try:\n",
    "            from IPython.display import clear_output\n",
    "            clear_output(wait=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "        grid = [['| ' for _ in range(self.maze_len)] +\n",
    "                [\"|\\n\"] for _ in range(self.maze_len)]\n",
    "        for punish in self.punish_states:\n",
    "            grid[punish[0]][punish[1]] = '|X'\n",
    "        grid[self.goal[0]][self.goal[1]] = '|G'\n",
    "        grid[self.seeker[0]][self.seeker[1]] = '|S'\n",
    "        print(''.join([''.join(grid_row) for grid_row in grid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec1d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.env.apis.task_settable_env import TaskSettableEnv\n",
    "\n",
    "\n",
    "class CurriculumEnv(AdvancedEnv, TaskSettableEnv):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        AdvancedEnv.__init__(self)\n",
    "\n",
    "    def difficulty(self):\n",
    "        return abs(self.seeker[0] - self.goal[0]) + \\\n",
    "               abs(self.seeker[1] - self.goal[1])\n",
    "\n",
    "    def get_task(self):\n",
    "        return self.difficulty()\n",
    "\n",
    "    def set_task(self, task_difficulty):\n",
    "        while not self.difficulty() <= task_difficulty:\n",
    "            self.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dcd250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curriculum_fn(train_results, task_settable_env, env_ctx):\n",
    "    time_steps = train_results.get(\"timesteps_total\")\n",
    "    difficulty = time_steps // 1000\n",
    "    print(f\"Current difficulty: {difficulty}\")\n",
    "    return difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db20214",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "import tempfile\n",
    "\n",
    "\n",
    "temp = tempfile.mkdtemp()\n",
    "\n",
    "trainer = (\n",
    "    DQNConfig()\n",
    "    .environment(env=CurriculumEnv, env_task_fn=curriculum_fn)\n",
    "    .offline_data(output=temp)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "for i in range(15):\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imitation_algo = (\n",
    "    DQNConfig()\n",
    "    .environment(env=AdvancedEnv)\n",
    "    .evaluation(off_policy_estimation_methods={})\n",
    "    .offline_data(input_=temp)\n",
    "    .exploration(explore=False)\n",
    "    .build())\n",
    "\n",
    "for i in range(10):\n",
    "    imitation_algo.train()\n",
    "\n",
    "imitation_algo.evaluate()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
