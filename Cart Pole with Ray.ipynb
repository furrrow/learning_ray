{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d9c153-7d5e-44ee-a620-d91d3bf8a2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 15:41:39,194\tWARNING deprecation.py:50 -- DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n",
      "2023-08-17 15:41:39,240\tWARNING deprecation.py:50 -- DeprecationWarning: `build_tf_policy` has been deprecated. This will raise an error in the future!\n",
      "2023-08-17 15:41:39,242\tWARNING deprecation.py:50 -- DeprecationWarning: `build_policy_class` has been deprecated. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ray.tune.logger import pretty_print\n",
    "from ray.rllib.algorithms.dqn import DQNConfig, DQN\n",
    "from ray.rllib.algorithms import Algorithm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28135f49-e48b-40d0-ae02-620317b9e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_config = False\n",
    "print_weights = False\n",
    "print_model = False\n",
    "checkpoint_dir = \"./CartPoleV1/RL_checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2fa96b2-b248-4002-bd2d-364998eb8004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ray.rllib.algorithms.dqn.dqn.DQNConfig at 0x7f88d81a5f70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = DQNConfig()\n",
    "config.resources(\n",
    "    num_gpus=0,\n",
    "    num_cpus_per_worker=1,\n",
    "    num_gpus_per_worker=0,\n",
    ")\n",
    "config.rollouts(\n",
    "    num_rollout_workers=1,\n",
    "    num_envs_per_worker=1,\n",
    "    create_env_on_local_worker=True,\n",
    ")\n",
    "config.environment(\n",
    "    env=\"CartPole-v1\",\n",
    "    # env_config={\"my_config\": \"value\"},\n",
    "    render_env=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5685334e-c3f6-4334-960b-432269a611f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 15:41:39,253\tWARNING deprecation.py:50 -- DeprecationWarning: `rllib/algorithms/simple_q/` has been deprecated. Use `rllib_contrib/simple_q/` instead. This will raise an error in the future!\n",
      "2023-08-17 15:41:40,750\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "\u001b[2m\u001b[36m(pid=37941)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37941)\u001b[0m 2023-08-17 15:41:43,804\tWARNING deprecation.py:50 -- DeprecationWarning: `build_tf_policy` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37941)\u001b[0m 2023-08-17 15:41:43,805\tWARNING deprecation.py:50 -- DeprecationWarning: `build_policy_class` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37941)\u001b[0m /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37941)\u001b[0m   if not isinstance(terminated, (bool, np.bool8)):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37941)\u001b[0m 2023-08-17 15:41:43,809\tWARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37941)\u001b[0m 2023-08-17 15:41:43,810\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37941)\u001b[0m 2023-08-17 15:41:43,810\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37941)\u001b[0m 2023-08-17 15:41:43,815\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.get_torch_categorical_class_with_temperature` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37941)\u001b[0m 2023-08-17 15:41:43,815\tWARNING deprecation.py:50 -- DeprecationWarning: `TorchPolicy` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37941)\u001b[0m 2023-08-17 15:41:43,815\tWARNING deprecation.py:50 -- DeprecationWarning: `EpsilonGreedy` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37941)\u001b[0m 2023-08-17 15:41:43,815\tWARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37941)\u001b[0m 2023-08-17 15:41:43,816\tWARNING deprecation.py:50 -- DeprecationWarning: `TargetNetworkMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37941)\u001b[0m 2023-08-17 15:41:43,818\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37941)\u001b[0m 2023-08-17 15:41:43,821\tWARNING env_runner_v2.py:297 -- Could not import gymnasium.envs.classic_control.rendering! Try `pip install gymnasium[all]`.\n",
      "2023-08-17 15:41:43,838\tWARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!\n",
      "2023-08-17 15:41:43,839\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!\n",
      "2023-08-17 15:41:43,840\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!\n",
      "2023-08-17 15:41:43,846\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.get_torch_categorical_class_with_temperature` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "2023-08-17 15:41:43,846\tWARNING deprecation.py:50 -- DeprecationWarning: `TorchPolicy` has been deprecated. This will raise an error in the future!\n",
      "2023-08-17 15:41:43,847\tWARNING deprecation.py:50 -- DeprecationWarning: `EpsilonGreedy` has been deprecated. This will raise an error in the future!\n",
      "2023-08-17 15:41:43,847\tWARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!\n",
      "2023-08-17 15:41:43,848\tWARNING deprecation.py:50 -- DeprecationWarning: `TargetNetworkMixin` has been deprecated. This will raise an error in the future!\n",
      "2023-08-17 15:41:43,851\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "2023-08-17 15:41:43,856\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing epoch 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 15:41:46,030\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to ./CartPoleV1/RL_checkpoints/checkpoint_000001\n",
      "trianing epoch 1...\n",
      "trianing epoch 2...\n",
      "trianing epoch 3...\n",
      "trianing epoch 4...\n",
      "trianing epoch 5...\n",
      "Checkpoint saved to ./CartPoleV1/RL_checkpoints/checkpoint_000006\n",
      "trianing epoch 6...\n",
      "trianing epoch 7...\n",
      "trianing epoch 8...\n",
      "trianing epoch 9...\n",
      "trianing epoch 10...\n",
      "Checkpoint saved to ./CartPoleV1/RL_checkpoints/checkpoint_000011\n",
      "agent_timesteps_total: 11000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.004956483840942383\n",
      "  StateBufferConnector_ms: 0.0033855438232421875\n",
      "  ViewRequirementAgentConnector_ms: 0.07801985740661621\n",
      "counters:\n",
      "  last_target_update_ts: 10501\n",
      "  num_agent_steps_sampled: 11000\n",
      "  num_agent_steps_trained: 320000\n",
      "  num_env_steps_sampled: 11000\n",
      "  num_env_steps_trained: 320000\n",
      "  num_target_updates: 20\n",
      "custom_metrics: {}\n",
      "date: 2023-08-17_15-44-06\n",
      "done: false\n",
      "episode_len_mean: 77.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 279.0\n",
      "episode_reward_mean: 77.92\n",
      "episode_reward_min: 11.0\n",
      "episodes_this_iter: 10\n",
      "episodes_total: 238\n",
      "hostname: jim-desktop\n",
      "info:\n",
      "  last_target_update_ts: 10501\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 9999.0\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.2951816916465759\n",
      "        max_q: 19.210893630981445\n",
      "        mean_q: 13.924233436584473\n",
      "        min_q: 1.2432724237442017\n",
      "      mean_td_error: 1.7126015424728394\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 32.0\n",
      "      num_grad_updates_lifetime: 10000.0\n",
      "      td_error: [0.04815864562988281, -0.24484634399414062, 0.24700355529785156, 0.20246028900146484,\n",
      "        2.8222811222076416, -0.0077800750732421875, 2.865651845932007, 0.00124359130859375,\n",
      "        -0.3734779357910156, 1.584834098815918, -0.088714599609375, 0.11324691772460938,\n",
      "        -0.0248565673828125, -0.21339797973632812, 15.256109237670898, 0.5811748504638672,\n",
      "        0.008419036865234375, -0.250244140625, 0.7155822515487671, 0.0305938720703125,\n",
      "        0.21408843994140625, -0.2387676239013672, 0.4388695955276489, 0.24327242374420166,\n",
      "        15.719614028930664, 0.05098724365234375, 0.22820281982421875, 0.2317829132080078,\n",
      "        -0.2843666076660156, -0.07978296279907227, 15.086008071899414, -0.08009719848632812]\n",
      "  num_agent_steps_sampled: 11000\n",
      "  num_agent_steps_trained: 320000\n",
      "  num_env_steps_sampled: 11000\n",
      "  num_env_steps_trained: 320000\n",
      "  num_target_updates: 20\n",
      "iterations_since_restore: 11\n",
      "node_ip: 192.168.0.136\n",
      "num_agent_steps_sampled: 11000\n",
      "num_agent_steps_trained: 320000\n",
      "num_env_steps_sampled: 11000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 70.89168275698832\n",
      "num_env_steps_trained: 320000\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 2268.533848223626\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 1\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 28.657142857142862\n",
      "  ram_util_percent: 31.642857142857153\n",
      "pid: 37361\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06382419608724473\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.036528355009721965\n",
      "  mean_inference_ms: 0.6394994271713909\n",
      "  mean_raw_obs_processing_ms: 0.4798966184733727\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.004956483840942383\n",
      "    StateBufferConnector_ms: 0.0033855438232421875\n",
      "    ViewRequirementAgentConnector_ms: 0.07801985740661621\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 77.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 279.0\n",
      "  episode_reward_mean: 77.92\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 10\n",
      "  hist_stats:\n",
      "    episode_lengths: [28, 30, 22, 26, 86, 19, 41, 11, 156, 14, 107, 126, 47, 54, 29,\n",
      "      23, 12, 20, 17, 97, 19, 21, 15, 38, 75, 13, 102, 59, 275, 34, 49, 114, 16, 18,\n",
      "      17, 58, 14, 45, 22, 22, 37, 134, 29, 26, 13, 22, 72, 66, 44, 29, 26, 30, 177,\n",
      "      189, 106, 105, 106, 130, 125, 175, 19, 58, 46, 186, 131, 37, 100, 279, 14, 135,\n",
      "      90, 186, 75, 138, 131, 113, 82, 28, 52, 80, 77, 13, 134, 126, 99, 103, 137,\n",
      "      141, 98, 128, 142, 147, 142, 152, 120, 36, 134, 104, 116, 31]\n",
      "    episode_reward: [28.0, 30.0, 22.0, 26.0, 86.0, 19.0, 41.0, 11.0, 156.0, 14.0,\n",
      "      107.0, 126.0, 47.0, 54.0, 29.0, 23.0, 12.0, 20.0, 17.0, 97.0, 19.0, 21.0, 15.0,\n",
      "      38.0, 75.0, 13.0, 102.0, 59.0, 275.0, 34.0, 49.0, 114.0, 16.0, 18.0, 17.0, 58.0,\n",
      "      14.0, 45.0, 22.0, 22.0, 37.0, 134.0, 29.0, 26.0, 13.0, 22.0, 72.0, 66.0, 44.0,\n",
      "      29.0, 26.0, 30.0, 177.0, 189.0, 106.0, 105.0, 106.0, 130.0, 125.0, 175.0, 19.0,\n",
      "      58.0, 46.0, 186.0, 131.0, 37.0, 100.0, 279.0, 14.0, 135.0, 90.0, 186.0, 75.0,\n",
      "      138.0, 131.0, 113.0, 82.0, 28.0, 52.0, 80.0, 77.0, 13.0, 134.0, 126.0, 99.0,\n",
      "      103.0, 137.0, 141.0, 98.0, 128.0, 142.0, 147.0, 142.0, 152.0, 120.0, 36.0, 134.0,\n",
      "      104.0, 116.0, 31.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06382419608724473\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.036528355009721965\n",
      "    mean_inference_ms: 0.6394994271713909\n",
      "    mean_raw_obs_processing_ms: 0.4798966184733727\n",
      "time_since_restore: 142.42789602279663\n",
      "time_this_iter_s: 14.108476638793945\n",
      "time_total_s: 142.42789602279663\n",
      "timers:\n",
      "  learn_throughput: 9523.31\n",
      "  learn_time_ms: 3.36\n",
      "  load_throughput: 370972.161\n",
      "  load_time_ms: 0.086\n",
      "  sample_time_ms: 3.581\n",
      "  synch_weights_time_ms: 0.61\n",
      "  training_iteration_time_ms: 14.25\n",
      "timestamp: 1692301446\n",
      "timesteps_total: 11000\n",
      "training_iteration: 11\n",
      "trial_id: default\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algo = config.build()\n",
    "policy = algo.get_policy()\n",
    "if print_weights: print(policy.get_weights())\n",
    "\n",
    "if print_model: print(policy.model)\n",
    "result = None\n",
    "for i in range(11):\n",
    "    print(f\"trianing epoch {i}...\")\n",
    "    result = algo.train()\n",
    "    if i % 5 == 0:\n",
    "        checkpoint = algo.save(checkpoint_dir)\n",
    "        print(f\"Checkpoint saved to {checkpoint}\")\n",
    "\n",
    "if result is not None:\n",
    "    print(pretty_print(result))\n",
    "algo.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96bbb85d-c305-4b4a-b941-3f176f6b0725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=38226)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38226)\u001b[0m 2023-08-17 15:44:09,491\tWARNING deprecation.py:50 -- DeprecationWarning: `build_tf_policy` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38226)\u001b[0m 2023-08-17 15:44:09,492\tWARNING deprecation.py:50 -- DeprecationWarning: `build_policy_class` has been deprecated. This will raise an error in the future!\n",
      "2023-08-17 15:44:09,523\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation:\n",
      "  connector_metrics: {}\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: .nan\n",
      "  episode_media: {}\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  hist_stats:\n",
      "    episode_lengths: []\n",
      "    episode_reward: []\n",
      "  num_agent_steps_sampled_this_iter: 10\n",
      "  num_env_steps_sampled_this_iter: 10\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  sampler_results:\n",
      "    connector_metrics: {}\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: .nan\n",
      "    episode_media: {}\n",
      "    episode_reward_max: .nan\n",
      "    episode_reward_mean: .nan\n",
      "    episode_reward_min: .nan\n",
      "    episodes_this_iter: 0\n",
      "    hist_stats:\n",
      "      episode_lengths: []\n",
      "      episode_reward: []\n",
      "    num_faulty_episodes: 0\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf: {}\n",
      "  timesteps_this_iter: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://docs.ray.io/en/latest/rllib/rllib-offline.html#off-policy-estimation-ope\n",
    "\n",
    "restored_algo = Algorithm.from_checkpoint(checkpoint)\n",
    "evaluation = restored_algo.evaluate()\n",
    "print(pretty_print(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c85a718-8f59-40a3-86b3-98b4507de5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./CartPoleV1/RL_checkpoints/checkpoint_000011'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d080130-08fc-402c-9ee4-bc09919fe377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=38226)\u001b[0m /home/jim/mambaforge/envs/ray/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38226)\u001b[0m   if not isinstance(terminated, (bool, np.bool8)):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38226)\u001b[0m 2023-08-17 15:44:09,496\tWARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38226)\u001b[0m 2023-08-17 15:44:09,496\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38226)\u001b[0m 2023-08-17 15:44:09,496\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38226)\u001b[0m 2023-08-17 15:44:09,501\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.get_torch_categorical_class_with_temperature` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38226)\u001b[0m 2023-08-17 15:44:09,501\tWARNING deprecation.py:50 -- DeprecationWarning: `TorchPolicy` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38226)\u001b[0m 2023-08-17 15:44:09,502\tWARNING deprecation.py:50 -- DeprecationWarning: `EpsilonGreedy` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38226)\u001b[0m 2023-08-17 15:44:09,502\tWARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38226)\u001b[0m 2023-08-17 15:44:09,502\tWARNING deprecation.py:50 -- DeprecationWarning: `TargetNetworkMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38226)\u001b[0m 2023-08-17 15:44:09,505\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38226)\u001b[0m 2023-08-17 15:44:09,508\tWARNING env_runner_v2.py:297 -- Could not import gymnasium.envs.classic_control.rendering! Try `pip install gymnasium[all]`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.0\n"
     ]
    }
   ],
   "source": [
    "# Note: `gymnasium` (not `gym`) will be **the** API supported by RLlib from Ray 2.3 on.\n",
    "import gymnasium as gym\n",
    "\n",
    "env_name = \"CartPole-v1\"\n",
    "env = gym.make(env_name, render_mode=\"human\")\n",
    "algo = restored_algo\n",
    "\n",
    "episode_reward = 0\n",
    "terminated = truncated = False\n",
    "\n",
    "obs, info = env.reset()\n",
    "\n",
    "while not terminated and not truncated:\n",
    "    action = algo.compute_single_action(obs)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "print(episode_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c1ce3-761b-446f-a5d9-e77995751d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cda6ff-3e47-4040-99ba-4a9894c71e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
